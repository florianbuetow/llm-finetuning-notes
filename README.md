# llm-finetuning-notes
Course Notes from [LLM Fine-Tuning for Data Scientists and Software Engineers](https://maven.com/parlance-labs/fine-tuning).

## Resources

#### AI Product Evaluation
- [Your AI Product Needs Evals](https://hamel.dev/blog/posts/evals/) (hamel.dev)
- [Langtrace AI - Monitor, eval & improve your LLM apps](https://langtrace.ai) (langtrace.ai)
- [Observability for LLMs](https://www.honeycomb.io/llm) (honeycomb.io)
- [Inspect, a framework for large language model evaluations created by the UK AI Safety Institute](https://ukgovernmentbeis.github.io/inspect_ai/) (ukgovernmentbeis.github.io)

#### Programming and Development Tools
- [DSPy: Programming—not prompting—Foundation Models](https://github.com/stanfordnlp/dspy) (github.com)
- [Cohere Toolkit to quickly build and deploy RAG apps](https://docs.cohere.com/docs/cohere-toolkit) (cohere.com)
- [Open UI](https://v0.dev) (v0.dev) and [Open UI GitHub](https://github.com/wandb/openui) (github.com)
- [Effortless Python web applications](https://shiny.posit.co/py/) (shiny.posit.co)
- [Fireworks’ GPT-4-level function calling model](https://fireworks.ai/blog/firefunction-v1-gpt-4-level-function-calling) (fireworks.ai)
- [Code for the Hermes Pro Large Language Model to perform function calling based on the provided schema](https://github.com/NousResearch/Hermes-Function-Calling) (github.com)
- [InternVL - A Pioneering Open-Source Alternative to GPT-4V](https://github.com/OpenGVLab/InternVL) (github.com)
- [Gorilla: Large Language Model Connected with Massive APIs](https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html) (gorilla.cs.berkeley.edu)
- [Notebook fine-tuning on a Captcha image dataset](https://github.com/vikhyat/moondream/blob/main/notebooks/Finetuning.ipynb) (github.com)
- [Get your LLM app from prototype to production](https://www.langchain.com/langsmith) (langchain.com)

#### Tokenization and Fine-Tuning
- [Tokenization Gotchas](https://hamel.dev/notes/llm/finetuning/05_tokenizer_gotchas.html) (hamel.dev)
- [Fine-tuning: Axolotl vs Unsloth vs TorchTune](https://swaroopch.com/notes/fine-tuning-library) (swaroopch.com)
- [Curating LLM data](https://hamel.dev/notes/llm/finetuning/04_data_cleaning.html) (hamel.dev)
- [Tools for curating LLM data](https://hamel.dev/notes/llm/04_data_cleaning.html) (hamel.dev)
- [Notebook fine-tuning on a Captcha image dataset](https://github.com/vikhyat/moondream/blob/main/notebooks/Finetuning.ipynb) (github.com)

#### Prompt Engineering
- [Anthropic's Prompt Engineering Interactive Tutorial](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8/htmlview?usp=sharing) (docs.google.com)
- [Fuck You, Show Me The Prompt](https://hamel.dev/blog/posts/prompt/) (hamel.dev)
- [Series: Prompt injection](https://simonwillison.net/series/prompt-injection/) (simonwillison.net)

#### Research Papers and Studies
- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/pdf/2212.08073) (arxiv.org)
- [The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions](https://arxiv.org/abs/2404.13208) (arxiv.org)
- [Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study](https://arxiv.org/abs/2404.10719) (arxiv.org)
- [RAFT: Adapting Language Model to Domain Specific RAG](https://arxiv.org/abs/2403.10131) (arxiv.org)
- [Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?](https://arxiv.org/abs/2405.05904) (arxiv.org)
- [Your Language Model is Secretly a Reward Model](https://arxiv.org/pdf/2305.18290) (arxiv.org)
- [The Unreasonable Ineffectiveness of the Deeper Layers](https://twitter.com/kwindla/status/1788224280754618393) (twitter.com)

#### News and Articles
- [Latent Space The AI Engineer newsletter](https://www.latent.space/p/fastai) (latent.space)
- [Air Canada Has to Honor a Refund Policy Its Chatbot Made Up](https://www.wired.com/story/air-canada-chatbot-refund-policy/) (wired.com)

#### Educational Content
- [YT video explaining transformers](https://www.youtube.com/watch?v=bCz4OMemCcA&t=5s) (youtube.com)
- [But what is a GPT? Visual intro to transformers | Chapter 5, Deep Learning](https://www.youtube.com/watch?v=wjZofJX0v4M) (youtube.com)
